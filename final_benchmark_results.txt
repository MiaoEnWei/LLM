å¼€å§‹å…¨è‡ªåŠ¨æ‰¹é‡è¯„ä¼°...
===========================================
ðŸ” åœ¨ [out_gpt2_official_prompt_tuning] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_official_prompt_tuning
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_official_prompt_tuning...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.12678469446030838,
  "rouge2": 0.039603960396039604,
  "rougeL": 0.09746811345897582,
  "rougeLsum": 0.11707595659623073
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
===========================================
ðŸ” åœ¨ [out_gpt2_official_prompt_tuning_e1] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_official_prompt_tuning_e1
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_official_prompt_tuning_e1...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.10620915032679738,
  "rouge2": 0.039999999999999994,
  "rougeL": 0.09640522875816994,
  "rougeLsum": 0.07734204793028322
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
===========================================
ðŸ” åœ¨ [out_gpt2_official_prompt_tuning_e2_nt20] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_official_prompt_tuning_e2_nt20/checkpoint-11428
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_official_prompt_tuning_e2_nt20/checkpoint-11428...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.05563186813186813,
  "rouge2": 0.0,
  "rougeL": 0.05563186813186813,
  "rougeLsum": 0.05563186813186813
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
===========================================
ðŸ” åœ¨ [out_gpt2_pubmedqa_decision_prompt_tuning] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_pubmedqa_decision_prompt_tuning/checkpoint-25000
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_pubmedqa_decision_prompt_tuning/checkpoint-25000...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.011235955056179777,
  "rouge2": 0.0,
  "rougeL": 0.011235955056179777,
  "rougeLsum": 0.011235955056179777
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
===========================================
ðŸ” åœ¨ [out_gpt2_pubmedqa_decision_prompt_tuning_v2] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_pubmedqa_decision_prompt_tuning_v2
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_pubmedqa_decision_prompt_tuning_v2...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.015151515151515154,
  "rouge2": 0.0,
  "rougeL": 0.015151515151515154,
  "rougeLsum": 0.007575757575757577
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
===========================================
ðŸ” åœ¨ [out_gpt2_pubmedqa_official_prompt_tuning] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_pubmedqa_official_prompt_tuning/checkpoint-12500
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_pubmedqa_official_prompt_tuning/checkpoint-12500...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.1846282372598162,
  "rouge2": 0.030534351145038167,
  "rougeL": 0.1695906432748538,
  "rougeLsum": 0.1620718462823726
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
===========================================
ðŸ” åœ¨ [out_gpt2_pubmedqa_prompt_tuning] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_pubmedqa_prompt_tuning/checkpoint-96
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_pubmedqa_prompt_tuning/checkpoint-96...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.1466369379412858,
  "rouge2": 0.04409388226240862,
  "rougeL": 0.12084726867335563,
  "rougeLsum": 0.11200297287253809
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
===========================================
ðŸ” åœ¨ [out_gpt2_pubmedqa_prompt_tuning_e2] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_pubmedqa_prompt_tuning_e2/checkpoint-50
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_pubmedqa_prompt_tuning_e2/checkpoint-50...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.05613477431659249,
  "rouge2": 0.0,
  "rougeL": 0.05613477431659249,
  "rougeLsum": 0.03960584869675778
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
===========================================
ðŸ” åœ¨ [out_gpt2_pubmedqa_prompt_tuning_e3] ä¸­å‘çŽ°æ¨¡åž‹ä½äºŽ: out_gpt2_pubmedqa_prompt_tuning_e3/checkpoint-200
/media/miaoen/ad4277ac-5cfe-47b0-a2cc-f9e50e0da444/LLM/.venv/lib/python3.10/site-packages/peft/peft_model.py:2066: UserWarning: Position ids are not supported for parameter efficient tuning. Ignoring position ids.
  warnings.warn("Position ids are not supported for parameter efficient tuning. Ignoring position ids.")
Reading data from data/pubmedqa/data/pqaa_labeled_test.parquet
Loading Base Model: ./gpt2 (Forcing FP32 for Stability)

Starting Inference for Base Model...

Loading Adapter from ./out_gpt2_pubmedqa_prompt_tuning_e3/checkpoint-200...

Starting Inference for PT Model...

Calculating ROUGE scores...

=== Base ROUGE ===
{
  "rouge1": 0.12217602217602218,
  "rouge2": 0.03669724770642201,
  "rougeL": 0.10415800415800416,
  "rougeLsum": 0.08613998613998614
}

=== PT   ROUGE ===
{
  "rouge1": 0.05613477431659249,
  "rouge2": 0.0,
  "rougeL": 0.05613477431659249,
  "rougeLsum": 0.03960584869675778
}

Analyzing cases (Top 1 significant samples)...
>>> Saving report for [Most_Improved_BaseLow_PTHigh] (1 samples) -> eval_out/report_Most_Improved_BaseLow_PTHigh.txt
>>> Saving report for [Most_Degraded_BaseHigh_PTLow] (1 samples) -> eval_out/report_Most_Degraded_BaseHigh_PTLow.txt
>>> Saving report for [Both_High] (1 samples) -> eval_out/report_Both_High.txt
>>> Saving report for [Both_Low] (1 samples) -> eval_out/report_Both_Low.txt

Saved details to eval_out/all_results.jsonl
